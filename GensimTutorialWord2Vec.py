# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ExSkCuLtHronjeeMLUq6emjB-fhVD2Vg
"""

import nltk
from nltk.corpus import brown
from collections import defaultdict, Counter
from gensim.models.word2vec import Word2Vec
from multiprocessing import cpu_count
import gensim.downloader as api

"""CODIGO DE GUILLERMO"""
def parse_Questions(corpus):
    counter = 0
    sentence_num = 0

    Vocab_v0 = dict()
    count = 0
    for sentence in corpus.sents(categories=['news']):
        for items in sentence :
            if items == '.':
                Vocab_v0[count] = sentence
                count = count + 1
    return Vocab_v0

lol = parse_Questions(brown)

"""FIN DE CODIGO DE GUILLERMO"""

"""CODIGO DE GENSIM TUTORIAL SOBRE WORD2VEC"""
# Download dataset
dataset = [lol[s] for s in lol]
data = [d for d in dataset]

# Split the data into 2 parts. Part 2 will be used later to update the model
data_part1 = data[:1000]
data_part2 = data[1000:]

# Train Word2Vec model. Defaults result vector size = 100
model = Word2Vec(data_part1, min_count = 0, workers=cpu_count())

# Get the word vector for given word
print(model['money'])
print("\n")

print(model.most_similar('money'))
print("\n")

# Save and Load Model
model.save('newmodel')
model = Word2Vec.load('newmodel')